# 来生小酒馆 2025/8/25

## Full: Podcast Formatting 

堆叠算力就能通往AGI吗？
几个工程师真能凭爱好造出AI芯片？
未来的AI，会成为你的“苏格拉底”吗？

三问炼心。嘿，亲爱的V，欢迎收听新一期的来生情报站，我是你们的老朋友，何夕2077。

好，咱们直入正题。这几天科技圈最能折腾的男人，马斯克，又出手了。他旗下的xAI，直接把Grok 2.5模型给开源了，代码就放那儿，谁都能看，谁都能用。不仅如此，他还放话了，说性能更进一步的Grok 3，半年内就来。哦对了，安卓用户心心念念的Vision模式，现在也全面开放了。这波操作，可以说是技术普惠了，对吧？

说到开放，国内这边也有新动作。上海AI实验室搞了个叫OpenDataArena的平台。你知道吧，以前咱们评估一个数据集好不好用，基本靠猜，跟“炼丹”似的，充满了玄学。现在这个平台，就像一个开放的“数据比武场”，把各种数据集拉到同一个标准下，用模型效果说话，谁是骡子谁是马，拉出来遛遛就知道。这下，模型训练总算能告别盲目试错了。

诶，说到比武，有几个加拿大的工程师小哥，那可真是上演了一出现实版的硬件界“黑客神话”。他们利用一个暑假的时间，从零基础开始，愣是手搓出了一块能推理、能训练的开源AI芯片，叫TinyTPU。据说啊，他们是从最基础的多层感知机概念学起，亲手推导数学公式，最后用他们自己说的“不靠谱的方法”……重新发明了TPU的核心。这种从0到1的创造，真是硬核又浪漫。

话说回来，无论是开源模型还是手搓芯片，大家最终的目标，不都是为了那个传说中的AGI，通用人工智能嘛。但现在有个问题，大模型的性能增长好像开始变慢了。所以有人就提出来，通往AGI的路，可能不是靠“大力出奇迹”，无休止地堆模型规模，而是一个精密的系统工程问题。什么意思呢？就是说，未来的突破点可能在于给AI模型构建一个更聪明的框架，包括更好的上下文、记忆和工作流系统。嗯……也许我们真该换个思路，像工程师一样去思考AGI了。

聊到这个话题，就不得不提谷歌大脑之父Jeff Dean。他最近在一个深度访谈里聊了好多有意思的事。他说，谷歌大脑这个项目，最初就诞生于一次茶水间的闲聊。而且他早在90年代，就预见到了并行计算对AI的巨大潜力。他把未来的AI模型比作一个可以和我们辩论、推理的“苏格拉底式伙伴”，还提出了一个设想，叫“一亿老师，一个学生”的时代。这个比喻，有点意思啊。

好了，聊了这么多宏大叙事，咱们也来点接地气的干货，盘点几个最近很火的开源项目。

第一个叫drawnix，一个全能的在线白板，什么思维导图、流程图、自由画画，它都能搞定，简直是协作工具里的“瑞士军刀”。
第二个，GhostTrack，一个功能很强的手机号码和位置追踪工具。这个……嗯，功能很强大，但大家一定要在合法合规的前提下使用啊。
第三个，DeepCode，这个好玩，号称“需求翻译机”，你可以把学术论文扔给它，它给你吐出代码，或者你用大白话描述一个网页，它就能帮你生成，非常适合开发者。
最后一个，mesh2motion-app，3D设计师和游戏开发者的福音。你把3D模型导进去，它能自动帮你绑定骨骼，导出动画，省了一大堆功夫。

最后，再分享几个社交媒体上的小道消息和独家秘笈。
首先，Reddit上有个帖子火了，讲怎么从零到一搭建自己的AI Agent，从设计到工具选择，保姆级教程，想创造自己智能体的朋友可以去看看。
其次，有个“邪修宝典”，教你怎么在LMArena里，把抽中那个P图效果惊艳的nano banana模型的概率，提高到三分之二。秘诀很简单，就是你提需求的时候，不管三七二十一，永远上传两张图，哪怕有一张是透明的像素点。
说到Nanobanana，谷歌这个新模型确实厉害，用简单的文字就能实现专业级的PS效果，换背景、调光影，几秒钟搞定。用文字“施法”修图，这感觉，妙啊。

今天的情报就到这里，注意隐蔽，赶紧撤离。

---
本期关键词:
#Grok
#xAI
#马斯克
#OpenDataArena
#上海AI实验室
#数据集评估
#TinyTPU
#开源AI芯片
#AGI
#系统工程
#Jeff Dean
#谷歌大脑
#苏格拉底式伙伴
#drawnix
#GhostTrack
#DeepCode
#mesh2motion-app
#AI Agent
#Nanobanana

## Short: Podcast Formatting 

造AI芯片，真能像搭乐高一样简单吗？
通往AGI的终点，是更大的模型还是更巧的系统？
如果AI成了你的“抬杠”伙伴，是福是祸？

三问炼心，嘿，亲爱的V，欢迎收听新一期的来生情报站，我是你们的老朋友，何夕2077。

咱们开门见山。这周，马斯克又来挥舞他的开源大旗了，宣布旗下的Grok 2.5模型代码全开放，而且性能更强的Grok 3已经在路上了，安卓用户心心念念的Vision模式也终于全面上线。

模型要好，数据得喂饱。但怎么知道喂的是山珍海味还是剩饭剩菜？上海AI实验室搞了个OpenDataArena，简单说就是个“数据比武大会”，让数据集们上台比划比划，用模型效果说话，告别炼丹玄学。

说到硬件，你可能觉得造芯片是巨头的专利。但几位加拿大的工程师表示不服，一个暑假，零基础愣是手搓出了一块能推理能训练的开源AI芯片，叫TinyTPU。这可真是硬核界的浪漫神话。

芯片都能自己造了，那AGI还远吗？最近有篇热文就说了，别老想着“大力出奇迹”，未来的突破口可能不在于无限堆料，而在于把AGI看成一个精密的系统工程，需要聪明的上下文、记忆和工作流来配合。

谷歌大脑之父Jeff Dean最近也分享了他的看法。他觉得未来的AI，会像个“苏格拉底式伙伴”，能陪你辩论、帮你推理。他还预言了一个“一亿老师，一个学生”的时代，听起来是不是有点意思？

当然，光说不练假把式，好用的开源项目也层出不穷。比如全能在线白板drawnix，堪称协作工具里的瑞士军刀；还有能把你的想法一键变代码的DeepCode，简直是“需求翻译机”；更有为3D模型自动绑骨骼做动画的mesh2motion-app，让创作轻松不少。

最后，社交媒体上也有不少实用分享。比如谷歌最新的Nanobanana模型，动动嘴皮子就能实现专业级的P图效果。还有大神手把手教你如何从零到一搭建自己的AI Agent，教程详细到家了。

今天的情报就到这里，注意隐蔽，赶紧撤离。

本期关键词:
#马斯克
#xAI
#Grok
#开源
#上海AI实验室
#OpenDataArena
#数据集
#AI芯片
#TinyTPU
#AGI
#系统工程
#Jeff Dean
#谷歌大脑
#Drawnix
#DeepCode