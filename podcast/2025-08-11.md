# 来生小酒馆 2025/8/11

## Full: Podcast Formatting 

AI创作，真能当饭吃吗？
AI模型，越大就越强吗？
你付费的AI工具，会不会正在偷偷烧光投资人的钱？

嘿，亲爱的V，欢迎收听新一期的来生情报站，我是你们的老朋友，何夕2077。

咱们今天先聊点实在的，钱。搞AI创作的朋友们，是不是还在“为爱发电”？字节跳动旗下的那个即梦AI平台，最近搞了个大动作，推出了一个“创作者成长计划”。说白了，就是想帮大家把创意变成真金白银。他们提供积分奖励、流量扶持，甚至还有字节系的商业订单……这套路，听着是不是有点耳熟？对，他们就是想复制抖音的成功，让AI创作也能成为一个正经的产业，而不是停留在小圈子的自娱自乐。

说起创作，诶，最近B站上就出了个超级爆款。一个纯AI制作的视频，一天播放量干到200万，直接冲上了全站排行榜。视频本身嘛，就是一个抠图人物，配上GPT-4o生成的黄绿色调背景。这说明啥？说明现阶段，你的想法和创意，可能比技术本身还重要。观众已经准备好拥抱纯AI内容了，就看你的脑洞够不够大。

当然了，工具也得跟上。OpenAI就干了件小而美的好事。以前用ChatGPT，总得猜它背后是哪个模型在干活，跟开盲盒似的。现在好了，你只要把鼠标放到那个“重新生成”的按钮上，模型版本就一目了然了。这个更新虽然小，但确实解决了无数人的一个“小烦恼”，值得点个赞。

聊完应用，咱们再看看前沿研究，这部分总能给人一些……嗯……智力上的冲击。

话说，有个被称为00后天才的王冠，他搞出来一个叫HRM的“分层推理模型”。这个模型有多大呢？27M。对，你没听错，就是27兆，比你手机里一张高清照片大不了多少。但就是这么个小家伙，在解数独、走迷宫这些需要推理的任务上，表现居然超过了像Claude 3.7这种参数大它几百上千倍的“大块头”。它的秘诀是模仿大脑，分了两层，一层负责宏观规划，一层负责具体计算。这事儿告诉我们，AI变强，不一定非得走“大力出奇迹”的路子，聪明的结构设计，同样能四两拨千斤。

另一个研究也很有意思。新加坡国立大学发现，一种叫“扩散语言模型”的东西，简直就是个数据榨汁机。把同一份数据喂给它学习480遍，它的性能还能蹭蹭往上涨，一点都不“消化不良”。这对于解决现在高质量数据越来越少的问题，算是个新思路了。看来我们对现有数据的价值，理解得还远远不够啊。

好，视线转向行业。腾讯的首席科学家张正友博士最近就说了，搞“具身智能”，也就是让机器人有身体有脑子，不能光想着给机器人装个大模型就完事了。他觉得，在数据还不够多的情况下，像他们提出的那个SLAP³分层架构，先让机器人跑起来，积累经验，是更务实的做法。这就像……你想登陆火星，总得先把能回收的火箭造出来，对吧？一步一步来，别被短期的商业利益晃花了眼。

不过，也不是所有大厂都这么稳。最近就有人火力全开，批评微软的Copilot平台（MCP），说它完全无视了过去几十年行业里最好的技术实践，简直是在“重复造一个方的轮子”。这话说的挺狠，但也给所有企业提了个醒：赶时髦追新技术没问题，但别把老祖宗传下来的好东西给扔了，不然最后可能要付出惨痛的代价。

说到代价……你每个月付费的AI编程助手，用着爽吧？但有分析指出，这玩意儿可能是在上演一出“VC慈善”大戏。因为AI每一次帮你写代码、分析问题的成本，也就是“推理成本”，可能远远超过了你付的那点订阅费。说白了，就是用得越多，亏得越惨，全靠风险投资在后面输血。未来的出路在哪？可能是拥抱开源，让定价更透明。否则，这个泡沫，迟早有破的一天。

最后，快速分享几个开源社区的好东西。如果你受够了复杂的网站分析工具，可以试试umami；想拥有一个完全离线运行、保障数据隐私的个人ChatGPT，可以玩玩Jan；信息太多关注不过来？Folo帮你一站式搞定。这些项目都在GitHub上热度很高，感兴趣的可以自己去搜搜看。

今天的情报就到这里，注意隐蔽，赶紧撤离。

---
本期关键词:
#即梦AI
#创作者成长计划
#HRM模型
#扩散语言模型
#推理成本
#具身智能
#SLAP³
#微软MCP
#OpenAI
#开源
#代码幻觉
#GPT-4o
#AI安全

## Short: Podcast Formatting 

你付费的AI，可能正在让VC做慈善？
大，就一定更强吗？
造轮子，还得是方的？

三问炼心。嘿，亲爱的V，欢迎收听新一期的来生情报站，我是你们的老朋友，何夕2077。

AI创作者们“为爱发电”的日子可能要到头了。字节跳动旗下的即梦AI平台，最近推出了一个创作者成长计划，从流量到商单，全方位扶持，目标很明确：复刻抖音的成功，让大家靠创意就能恰上饭。

说到用户体验，OpenAI也干了件贴心的小事。现在你用ChatGPT，只要把鼠标悬停在“Regen”菜单上，就能一眼看清用的是哪个模型版本了，总算不用再玩“猜猜我是谁”的游戏。

模型界最近也挺热闹，流行起了“浓缩就是精华”。00后天才王冠，带着他那个只有27M的小模型HRM，在解数独、走迷宫这些推理任务上，居然把Claude 3.7这种大块头给比下去了。与此同时，新加坡国立大学发现，扩散语言模型DLM简直是数据榨汁机，一份数据能反复学习480遍，性能还蹭蹭涨，这下可算给“高质量数据不够用”这个老大难问题，提供了新思路。

视线转向行业，腾讯的首席科学家张正友博士说了，搞具身智能不能光想着给机器人装个大脑就完事儿，得务实。他提出的SLAP³分层架构，意思就是咱们先别一步登天，先造个能用的火箭跑起来再说。

有人务实，就有人被吐槽“开倒车”。微软的Copilot平台MCP，就被一篇火力全开的评论狠批，说它无视了快半个世纪的技术积累，非要自己造个方的轮子，这可把依赖它的企业给吓出一身冷汗。

说到企业，你每月付费的AI编程助手，可能正在上演一出“VC慈善”大戏。高昂的推理成本远超订阅费，全靠风险投资输血。有分析就指出，这泡沫迟早要破，未来的出路还得是拥抱开源和透明定价。

既然说到开源，好东西还真不少。想断网也能用ChatGPT？可以试试Jan。想换掉谷歌分析保护隐私？umami是个不错的选择。想把各种信息流聚合到一起？Folo能帮你。安卓玩家的老朋友Magisk依然强大，还有个叫GitMCP的项目，专门治AI代码生成时的“胡言乱语”。

最后看看社交媒体上的动态。DAIR.AI照例打包了本周必读的AI论文清单，帮你跟上学术前沿。B站上一个纯AI制作的视频，一天拿下200万播放，这说明啥？观众已经准备好了，现在就看创作者的脑洞有多大了。不过，在评估AI时也得多个心眼，有专家就指出，《纽约时报》测试AI幻觉的方法有偏差，他们测的是“纠正错误”的能力，而不是“从不犯错”的能力，这可完全是两码事。

今天的情报就到这里，注意隐蔽，赶紧撤离。

---
**本期关键词:**
#字节跳动
#即梦AI
#创作者成长计划
#商业变现
#HRM模型
#推理能力
#扩散语言模型
#AI编程助手
#推理成本
#商业模式
#腾讯
#具身智能
#微软MCP
#技术选型
#OpenAI
#开源工具
#隐私
#本地化